# sido-ML_inference_docker_fastAPI
my minimal template to create an api for ML model inference on clouds

(then use docker to deploy or systemctl)
