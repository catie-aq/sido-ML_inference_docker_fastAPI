# sido-ML_inference_docker_fastAPI
my minimal template to create an api for ML model inference
(then use docker to deploy or systemctl)
